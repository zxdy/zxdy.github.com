<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>RSS feed title</title>
        <link>Homepage link</link>
        <description>RSS feed description</description>
        <lastBuildDate>Fri, 20 Mar 2015 15:01:09 +0800</lastBuildDate>
        <language>zh-cn</language>
        
        <item>
            <title>oracle性能优化-CPU篇(下)</title>
            <link>Homepage link/articles/oracle-tunning-cpu-2.html?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=rss</link>
            <guid>Homepage link/articles/oracle-tunning-cpu-2.html</guid>
            <author>zxdy@vip.qq.com Ario</author>
            <pubDate>Tue, 10 Mar 2015 00:00:00 +0800</pubDate>
            <description>&lt;p&gt;接上篇 &lt;a href=&quot;http://zxdy.github.io/articles/oracle-tunning-cpu-1.html&quot;&gt;oracle性能优化-CPU篇(上)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;如何有效利用好CPU，主要在于如何写好SQL语句， 并优化数据库内部处理。&lt;/p&gt;
&lt;h2 id=&quot;1-sql语句重用&quot;&gt;1. sql语句重用&lt;/h2&gt;
&lt;h3 id=&quot;11-硬解析与软解析&quot;&gt;1.1 硬解析与软解析&lt;/h3&gt;
&lt;p&gt;相信用过oracle的人，特别是用oracle做后端数据库开发的程序猿都听说过硬解析和软解析。&lt;/p&gt;
&lt;p&gt;当一个sql语句提交后，oracle会首先检查一下共享缓冲池（shared pool）里有没有与之&lt;strong&gt;完全相同&lt;/strong&gt;的语句，如果有的话只须执行软分析即可，否则就得进行硬分析。&lt;/p&gt;
&lt;p&gt;硬解析之所以坑爹的原因是，它需要经解析,制定执行路径,优化访问计划等许多的步骤。不但耗费大量的cpu，更重要的是会占据重要的们闩（latch）资源，严重的影响系统的规模的扩大（即限制了系统的并发行），而且引起的问题不能通过增加内存条和cpu的数量来解决。&lt;/p&gt;
&lt;p&gt;看一眼AWR报表，检查是不是有很多硬解析。下图的硬解析数和 time model statistics的hard parse elapsed time对应，可知该系统是否 是 解析敏感&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://zxdy-blog.qiniudn.com/hard_prase.png&quot; alt=&quot;hard parse&quot;&gt;&lt;/p&gt;
&lt;p&gt;有时候当我们在oracle上对某些sql进行测试时，会发现第一次执行的sql比较慢，再次执行往往都比较快，这不仅仅是因为所需要的数据块已经读取到buffer cache中了，还因为再次执行的sql沿用的是上次执行的执行计划，并没有重新做解析。&lt;/p&gt;
&lt;p&gt;因此假如我们需要测试相同sql不同的执行计划时，最好刷新一下当前session的shared pool。注意最好不要全局刷新，特别是在生产环境，这样会导致所有的sql都进行重新解析，可能会严重影响性能。&lt;/p&gt;
&lt;h3 id=&quot;12-绑定变量&quot;&gt;1.2 绑定变量&lt;/h3&gt;
&lt;p&gt;绑定变量的实质就是用于替代sql语句中的常量的替代变量，它能够使得每次提交的sql语句都完全一样。还记得前面说的&quot;oracle会首先检查一下共享缓冲池（shared pool）里有没有与之&lt;strong&gt;完全相同&lt;/strong&gt;的语句&quot;没有？
类似这样：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://zxdy-blog.qiniudn.com/bind_var.png&quot; alt=&quot;bind var&quot;&gt;&lt;/p&gt;
&lt;p&gt;一般来说，在实际的开发场景，只要使用比较成熟的数据持久层框架例如mybatis等，基本都可以避免这种因为没有用绑定变量而产生的性能问题。&lt;/p&gt;
&lt;h3 id=&quot;13-索引优化&quot;&gt;1.3 索引优化&lt;/h3&gt;
&lt;p&gt;索引优化这是大坑。。有空新开一篇再写吧&lt;/p&gt;
&lt;h2 id=&quot;2-表连接&quot;&gt;2. 表连接&lt;/h2&gt;
&lt;p&gt;在CBO（hash join只有在CBO才可能被使用到）模式下，优化器计算代价时，首先会考虑hash join。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;hash join的主要资源消耗在于CPU和内存（在内存中创建临时的hash表，并hash计算， Mem访问速度是Disk的万倍以上。）&lt;/li&gt;
&lt;li&gt;Nested Loop资源消耗在磁盘IO和CPU。&lt;/li&gt;
&lt;li&gt;sort merge的资源消耗主要在于磁盘IO（扫描表或索引）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;相对来说，比较常见的还是hash join以及nested loop。&lt;/p&gt;
&lt;p&gt;表连接科普参见 &lt;a href=&quot;http://blog.csdn.net/tianlesoftware/article/details/5826546&quot;&gt;多表连接的三种方式&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;22-hash-join&quot;&gt;2.2 hash join&lt;/h3&gt;
&lt;p&gt; Hash join的工作方式是将一个表（通常是小一点的那个表）做hash运算，将列数据存储到hash列表中，从另一个表中抽取记录，做hash运算，到hash 列表中找到相应的值，做匹配。&lt;/p&gt;
&lt;h3 id=&quot;22-nested-loop&quot;&gt;2.2 nested loop&lt;/h3&gt;
&lt;p&gt;Nested loops 工作方式是从一张表中读取数据，访问另一张表（通常是索引）来做匹配，nested loops适用的场合是当一个关联表比较小的时候，效率会更高。&lt;/p&gt;
&lt;h3 id=&quot;22-sort-merge&quot;&gt;2.2 sort merge&lt;/h3&gt;
&lt;p&gt;Merge Join 是先将关联表的关联列各自做排序，然后从各自的排序表中抽取数据，到另一个排序表中做匹配，因为merge join需要做更多的排序，所以消耗的资源更多。 通常来讲，能够使用merge join的地方，hash join都可以发挥更好的性能。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;总的来说，小表和大表连接用nested loop，大表和大表连接用hash join，关联列已经排序好的表连接推荐用sort merge（用的不多就是了）。
但凡事总有例外，具体的执行效果还是要根据具体情况看，有时候CBO推荐的执行计划未必是最好的， 此时你可以尝试使用hint或者修改sql语句来改变表连接。&lt;/p&gt;
&lt;/blockquote&gt;
</description>
        </item>
        
        <item>
            <title>oracle性能优化-CPU篇(上)</title>
            <link>Homepage link/articles/oracle-tunning-cpu-1.html?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=rss</link>
            <guid>Homepage link/articles/oracle-tunning-cpu-1.html</guid>
            <author>zxdy@vip.qq.com Ario</author>
            <pubDate>Wed, 04 Mar 2015 00:00:00 +0800</pubDate>
            <description>&lt;p&gt;在任何一样计算机软件产品中，当我们需要考虑其性能的时候，往往都会从CPU，IO，Network这三个方面考虑。CPU代表着处理问题的能力，IO代表着存储的吞吐能力，Network代表着数据传输的能力。oracle当然也不例外。&lt;/p&gt;
&lt;p&gt;下图反映的是一个应用程序总体的响应时间的分布情况。用户在前端发出数据的请求之后，经过网络层，到达数据库服务器。数据库服务器接收请求，然后对SQL进行语法语义分析，然后生成执行计划，接着执行sql，取得数据最后再次经过网络层返回到前端展现给用户。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://zxdy-blog.qiniudn.com/bottle-neck-of-oracle.png&quot; alt=&quot;bottle-neck-of-oracle&quot;&gt;&lt;/p&gt;
&lt;p&gt;很显然 &lt;strong&gt;oracle的处理时间=cpu处理时间+[资源等待时间+Disk IO 等待时间]&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;根据以上公式，我们可以发现只要能有效地利用cpu资源和降低等待时间就可以提高数据库的性能，使它处理得更快。&lt;/p&gt;
&lt;p&gt;这篇文章主要关注oracle sql在cpu上的性能优化。个人感觉相比等待上的优化简单一些，等待很多时候涉及到并发，资源争用，数据块等知识，优化也更加复杂不好下手。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;那么问题来了：&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;1-首先，怎么查看cpu信息&quot;&gt;1. 首先，怎么查看CPU信息&lt;/h2&gt;
&lt;p&gt;CPU的多少在很大程度上（质量也是很重要滴）决定了数据库性能的好坏。越多的CPU，可以并发的数目就越多。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;用系统命令查看。这里我默认认为oracle是安装在linux服务器上，当然装在windows上的不是没有，只是略奇葩了。&lt;/p&gt;
&lt;p&gt;  refer to  &lt;a href=&quot;http://zxdy.github.io/articles/linux-info-check.html&quot;&gt;查看cpu信息&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;sql查询NUM_CPUS字段。v$osstat这张表包含了很多有用的信息
附上&lt;a href=&quot;http://docs.oracle.com/cd/E11882_01/server.112/e40402/dynviews_2085.htm#REFRN30321&quot;&gt;官方文档&lt;/a&gt;解释&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&quot;prettyprint linenums lang-sql&quot;&gt;SELECT * FROM v$osstat;
&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;awr报告。在awr中会有cpu相关的各种报告，包括硬件信息以及更重要的性能信息。关于cpu的性能分析我会在后面展开。下面这张图展现了当前实例使用的cpu硬件信息。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;http://zxdy-blog.qiniudn.com/awr_cpu.png&quot; alt=&quot;awr cpu&quot;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;CPUs: 逻辑cpu数
Cores: cpu核数
Sockets: 物理cpu数&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;2-怎么看cpu的性能&quot;&gt;2. 怎么看CPU的性能&lt;/h2&gt;
&lt;p&gt;上面的CPU硬件信息只是帮助我们有个初步的概念，如果说你的数据库性能很差，CPU又很烂，很烂还没几个，那你真的该先换CPU了。。&lt;/p&gt;
&lt;p&gt;换完CPU，我们先来了解下下面这两个概念：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;host cpu&lt;/li&gt;
&lt;li&gt;instance cpu&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在AWR报告中会有这样两个不同的分类，像是这样&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://zxdy-blog.qiniudn.com/awr_cpu.png&quot; alt=&quot;host cpu&quot;&gt;&lt;/p&gt;
&lt;p&gt;还有这样&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://zxdy-blog.qiniudn.com/instance_cpu.png&quot; alt=&quot;instance cpu&quot;&gt;&lt;/p&gt;
&lt;p&gt;它们其实是分别代表了服务器cpu的负载和oracle实例的负载情况。&lt;/p&gt;
&lt;p&gt;对于host cpu：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&quot;Load Average&quot; begin/end值代表CPU的大致运行队列大小。上图中快照开始
到结束，平均 CPU负载减少了。&lt;/li&gt;
&lt;li&gt;%User+%System=&gt; 总的CPU使用率，在这里是5.7%。&lt;/li&gt;
&lt;li&gt;Busy Time=Elapsed Time * NUM_CPUS * CPU utilization&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对于instance cpu:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;%Total CPU,该实例所使用的CPU占总CPU的比例 -&gt; % of total CPU for
Instance&lt;/li&gt;
&lt;li&gt;%Busy CPU，该实例所使用的Cpu占总的被使用CPU的比例 -&gt; % of busy CPU for Instance。例如共4个逻辑CPU，其中3个被完全使用， 3个中的1 个完全被该实例使用，则%Total CPU= 1/4 =25%，而%Busy CPU= 1/3= 33%&lt;/li&gt;
&lt;li&gt;当CPU高时一般看%Busy CPU可以确定CPU到底是否是本实例消耗的，还是
主机上其他程序。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;身为一个开发我还要时不时看awr报告也是蛮拼的。一般来讲，awr更多的是展现数据库整体上的性能分析，你可能在以上的host cpu以及instance cpu上发现cpu的负载很高，但这又有什么用呢？是不是觉得没法继续了呢？当然不是，awr还提供了更多的详细的报告帮助我们定位哪些sql的cpu占用比较厉害：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;AWR SQL ordered by Elapsed Time：&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;http://zxdy-blog.qiniudn.com/sql_order_by_elapsed_time.png&quot; alt=&quot;AWR SQL ordered by Elapsed Time&quot;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;%CPU - CPU Time as a percentage of Elapsed Time -&gt; 这个语句耗费的DB TIME里CPU TIME占多少比例 -&gt; 这个语句是否是CPU敏感的&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;2.AWR SQL ordered by CPU Time：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://zxdy-blog.qiniudn.com/sql_order_by_cpu_time.png&quot; alt=&quot;AWR SQL order by cpu time&quot;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;第一列CPU TIME统计这个sql总共在快照时间内总共花费的cpu时间，在这个值比较高的情况下，如果相应的%CPU值也很高， 说明这个sql在cpu上的负载很高，需要考虑优化。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;如果发现有比较突出的sql，很可能就是瓶颈所在，可以继续跑个@?/rdbms/admin/awrsqrpt.sql看看&lt;/strong&gt;&lt;/p&gt;
</description>
        </item>
        
        <item>
            <title>oracle性能优化-执行计划篇</title>
            <link>Homepage link/articles/oracle-tunning-sqlplan.html?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=rss</link>
            <guid>Homepage link/articles/oracle-tunning-sqlplan.html</guid>
            <author>zxdy@vip.qq.com Ario</author>
            <pubDate>Mon, 09 Feb 2015 00:00:00 +0800</pubDate>
            <description>&lt;h1 id=&quot;执行计划？&quot;&gt;执行计划？&lt;/h1&gt;
&lt;p&gt;执行计划是sql在数据库中最终的执行路径，包括索引的扫描，数据的读取，过滤，连接，排序等等一系列过程。就像平常在生活中你为了完成一个任务，需要经过很多步骤，如果没有很好的统筹规划，任务时间会不断延长。所以sql的效率跟它的执行计划息息相关，同一个sql可能会有很多不一样的执行计划，基于CBO的oracle会在其中挑选出它认为最快的执行计划进行执行。下面这个流程图展现了优化器选择执行计划过程：&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;http://zxdy-blog.qiniudn.com/sql%20plan.png&quot; alt=&quot;优化器选择执行计划过程&quot;&gt;&lt;/p&gt;
&lt;p&gt; 从上面的流程图可以知道一个高效良好的执行计划需要考虑的因素有&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;绑定变量。//还记得CPU优化篇的sql重用吗&lt;/li&gt;
&lt;li&gt;统计信息。oracle默认会在每天的晚上以及周末触发自动收集数据改变量在10%以上的表的统计信息。如果统计信息过于陈旧，DBA或者开发也可以手动提交收集统计信息任务。&lt;/li&gt;
&lt;li&gt;hint。hint会强制指定执行计划的路径，比如select /*+ use_hash*/ ,不管优化器怎么认为表连接应该使用nested loop更加效率，都会强制使用hash连接&lt;/li&gt;
&lt;li&gt;sql profile。&lt;a href=&quot;https://docs.oracle.com/database/121/TGSQL/tgsql_profiles.htm#TGSQL599&quot;&gt;定义&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;sql plan。&lt;a href=&quot;https://docs.oracle.com/database/121/TGSQL/tgsql_spm.htm#TGSQL617&quot;&gt;sql profile vs plan baseline&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&quot;怎么查看执行计划&quot;&gt;怎么查看执行计划&lt;/h1&gt;
&lt;h2 id=&quot;1-explain-plan-for-sql&quot;&gt;1. Explain Plan For SQL&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;不实际执行SQL诧句，生成的计划未必是真实执行的计划 &lt;/li&gt;
&lt;li&gt;必须要有plan_table&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&quot;prettyprint linenums lang-SQL&quot;&gt;EXPLAIN PLAN FOR
  SELECT object_id FROM dba_objects;
SELECT PLAN_TABLE_OUTPUT FROM TABLE(DBMS_XPLAN.DISPLAY());
&lt;/pre&gt;
&lt;h2 id=&quot;2-sqlplus-autotrace&quot;&gt;2. SQLPLUS AUTOTRACE&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;除set autotrace traceonly explain外均实际执行SQL，但仍未必是真实计划&lt;/li&gt;
&lt;li&gt;必须要有plan_table&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;3-其他第三方工具&quot;&gt;3. 其他第三方工具&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;sqldeveloper&lt;/li&gt;
&lt;li&gt;toad（收费，比sqldeveloper强大，细节丰富）&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;4-最靠谱的方法&quot;&gt;4. 最靠谱的方法&lt;/h2&gt;
&lt;p&gt;为什么上文说未必是真实的计划呢？这里的指的是实际生产环境使用的执行计划和你手动用上文的方法查看某个sql的执行计划是有可能有差异的。所以最靠谱的办法是在生产环境找到已经执行过的sql或者是正在执行的sql的sql id，然后根据这个id去查看他的执行计划&lt;/p&gt;
&lt;h3 id=&quot;查询历史sql和sql-id&quot;&gt;查询历史sql和sql id&lt;/h3&gt;
&lt;pre class=&quot;prettyprint linenums lang-SQL&quot;&gt;select sql_id,sql_text from v$SQL Where
sql_text not like &#39;%like%&#39;
and sql_text like &#39;%$SQL%&#39;;
--或者
select b.SQL_TEXT,b.FIRST_LOAD_TIME,b.SQL_FULLTEXT
from v$sqlarea b
where b.FIRST_LOAD_TIME between &#39;2014-10-15/09:24:47&#39; and
&#39;2014-10-15/09:24:47&#39; order by b.FIRST_LOAD_TIME
&lt;/pre&gt;
&lt;h3 id=&quot;查询正在执行的sql和sql-id&quot;&gt;查询正在执行的sql和sql id&lt;/h3&gt;
&lt;pre class=&quot;prettyprint linenums lang-SQL&quot;&gt;select a.username, a.sid,b.SQL_TEXT, b.SQL_FULLTEXT,b.sql_id
from v$session a, v$sqlarea b 
where a.sql_address = b.address ;
&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;note:&lt;/p&gt;
&lt;p&gt;V\$SQL, V\$SQLAREA, V\$SQLTEXT三个视图的区别:&lt;/p&gt;
&lt;p&gt;V\$SQL：CHILD CURSOR DETAILS FOR V\$SQLAREA&lt;/p&gt;
&lt;p&gt;V\$SQLAREA：SHARED POOL DETAILS FOR STATEMENTS/ANONYMOUS BLOCKS&lt;/p&gt;
&lt;p&gt;V\$SQLTEXT：SQL TEXT OF STATEMENTS IN THE SHARED POOL&lt;/p&gt;
&lt;p&gt;V\$SQL的每一行表示的是每一个SQL语句的一个版本，而V\$SQLAREA存放的是相同语句不同版本一个GROUP BY汇总。&lt;/p&gt;
&lt;p&gt;V\$SQL及V\$SQLAREA存放着统计信息在调优时使用居多，但其SQL是不全的，如果想获得完整的SQL需使用V\$SQLTEXT。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;精确查询详细执行计划&quot;&gt;精确查询详细执行计划&lt;/h3&gt;
&lt;pre class=&quot;prettyprint linenums lang-SQL&quot;&gt;alter session set STATISTICS_LEVEL = ALL; --不设置无法获得A-ROWS等信息,A-Rows 是实际执行时返回的行数
select * from table(dbms_xplan.display_cursor(&#39;sql_id&#39;,null,&#39;ADVANCED ALLSTATS LAST PEEKED_BINDS&#39;));
&lt;/pre&gt;
&lt;h1 id=&quot;执行计划的执行顺序&quot;&gt;执行计划的执行顺序&lt;/h1&gt;
&lt;p&gt;toad看这个最方便，可以直接显示执行顺序。如图中的12345678就是：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://zxdy-blog.qiniudn.com/sqlplan_toad.png&quot; alt=&quot;sql plan by toad&quot;&gt;&lt;/p&gt;
&lt;p&gt;但是如果没有toad的话，通常显示的结果会是这样，要注意的是这里的id并不是顺序：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://zxdy-blog.qiniudn.com/sqlplan_sqldeveloper.png&quot; alt=&quot;sql plan&quot;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;note:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Id 分配给执行计划中每一个步骤的一个数字 每个步骤（执行计划中的行，戒树中的节点）代表行源 (row source)。&lt;/li&gt;
&lt;li&gt;Operation 该步骤实施的内部操作名 id=0的operation一般是 SELECT/INSERT/UPDATE/DELETE Statement&lt;/li&gt;
&lt;li&gt;Name 该步骤操作的表戒者索引名&lt;/li&gt;
&lt;li&gt;Rows CBO基亍统计信息估计该操作将返回的行数&lt;/li&gt;
&lt;li&gt;Bytes CBO基亍统计信息估计该操作将返回的字节数&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;如果你学过二叉树的后序遍历的话，其实也很简单。首先我们先将这个图根据缩进转化成一个树。然后对这个树进行一下后续遍历，这个遍历的顺序（4 -&gt; 6 -&gt; 5-&gt; 3 -&gt; 7 -&gt; 2 -&gt; 8 -&gt; 1 -&gt; 0）就是执行顺序。&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;http://zxdy-blog.qiniudn.com/tree.png&quot; alt=&quot;执行计划树&quot;&gt;&lt;/p&gt;
&lt;h1 id=&quot;如何通过执行计划优化sql&quot;&gt;如何通过执行计划优化sql&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;在计划中，驱动表具有最强的过滤性。&lt;/li&gt;
&lt;li&gt;每个步骤的联接顺序都可保证返回给下一步的行数最少（即，联接顺序应使系统转到尚未使用的最强过滤器）。&lt;/li&gt;
&lt;li&gt;就返回的行数而言，相应的联接方法是适合的。例如，返回的行很多时，使用索引的嵌套循环联接可能不是最佳方法。&lt;/li&gt;
&lt;li&gt;高效地使用视图。查看 SELECT 列表，确定访问的视图是否必需。&lt;/li&gt;
&lt;li&gt;是否存在预料之外的笛卡尔积（即使对于小表，也是如此）。&lt;/li&gt;
&lt;li&gt;高效地访问每个表：考虑 SQL 诧句中的谓词和表的行数。查找可疑活劢，例如对行数很多的表执行全表扫描（在 WHERE 子句中有谓词）。而对亍小表，戒根据返回的行数利用更好的联接方法（例如 hash_join）时，全表扫描也许更有效。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;参考：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;http://t.askmaclean.com/thread-3237-1-1.html&quot;&gt;Maclean Liu的Oracle性能优化讲座 真正读懂Oracle SQL执行计划&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.itpub.net/22664653/viewspace-701711/&quot;&gt;如何清除某条SQL在库缓存中的执行计划：dbms_shared_pool.purge &lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://files.cnblogs.com/files/kerrycode/ORACLE_11g_ARCHITECTURE.pdf&quot;&gt;oracle 11g 架构图&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        
        <item>
            <title>大文件读写效率比较</title>
            <link>Homepage link/articles/file-read-write-compare.html?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=rss</link>
            <guid>Homepage link/articles/file-read-write-compare.html</guid>
            <author>zxdy@vip.qq.com Ario</author>
            <pubDate>Thu, 15 Jan 2015 00:00:00 +0800</pubDate>
            <description>&lt;p&gt;之前做到一个大日志文件（size &gt; 1G）解析的项目，在此记录下对于大文本解析方式的效率比较。不同方式的性能差别很大，那个项目的日志解析时间能从原来的超过36小时优化到只需要2分钟，awk功不可没。&lt;/p&gt;
&lt;h2 id=&quot;bash-比较&quot;&gt;bash 比较&lt;/h2&gt;
&lt;p&gt;bash脚本中对于文本的读取主要有以下四种，尽管 AWK 具有完全属于其本身的语法，但在此我也把它归在一起：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-bash&quot;&gt;#方法一
func1(){
    rm -f $2
    echo &quot;$(date) start to read&quot;
    start_time=$(date +%s)
    cat $1|while read Line
    do
        echo $Line &gt;&gt; $2
    done
    end_time=$(date +%s)
    echo &quot;$(date) end to read&quot;
    echo &quot;cost: &quot;$((end_time-start_time))&quot;sec&quot;
}

#方法二
func2(){
    rm -f $2
    echo &quot;$(date) start to read&quot;
    start_time=$(date +%s)
    while read Line
    do
        echo $Line &gt;&gt; $2
    done &lt;$1
    end_time=$(date +%s)
    echo &quot;$(date) end to read&quot;
    echo &quot;cost: &quot;$((end_time-start_time))&quot;sec&quot;
}

#方法三
func3(){
    rm -f $2
    echo &quot;$(date) start to read&quot;
    start_time=$(date +%s)
    for Line in `cat $1`
    do
        echo $Line &gt;&gt; $2
    done
    end_time=$(date +%s)
    echo &quot;$(date) end to read&quot;
    echo &quot;cost: &quot;$((end_time-start_time))&quot;sec&quot;
}

#func4
func4(){
    rm -f $2
    echo &quot;$(date) start to read&quot;
    start_time=$(date +%s)
    awk &#39;{print $0}&#39; $1 &gt; $2
    echo &quot;$(date) end to read&quot;
    echo &quot;cost: &quot;$((end_time-start_time))&quot;sec&quot;
}


source=$1
dest=$2

#比较结果：
echo &quot;####cat read: &quot;
func1 $source $dest
echo &quot;####redirect read: &quot;
func2 $source $dest
echo &quot;####for read: &quot;
func3 $source $dest
echo &quot;####awk read: &quot;
func4 $source $dest
&lt;/pre&gt;
&lt;p&gt;结果:&lt;/p&gt;
&lt;p&gt;cat read:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Thu Jan 15 07:57:50 GMT 2015 start to read&lt;/p&gt;
&lt;p&gt;Thu Jan 15 07:58:33 GMT 2015 end to read&lt;/p&gt;
&lt;p&gt;cost: 43sec&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;redirect read:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Thu Jan 15 07:58:33 GMT 2015 start to read&lt;/p&gt;
&lt;p&gt;Thu Jan 15 07:59:01 GMT 2015 end to read&lt;/p&gt;
&lt;p&gt;cost: 28sec&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;for read:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Thu Jan 15 07:59:01 GMT 2015 start to read&lt;/p&gt;
&lt;p&gt;Thu Jan 15 08:00:00 GMT 2015 end to read&lt;/p&gt;
&lt;p&gt;cost: 59sec&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;awk read:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Thu Jan 15 08:00:00 GMT 2015 start to read&lt;/p&gt;
&lt;p&gt;Thu Jan 15 08:00:00 GMT 2015 end to read&lt;/p&gt;
&lt;p&gt;cost: 0sec&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;从以上结果可以看出，awk的效率远超其他方法&lt;/p&gt;
&lt;h2 id=&quot;python-比较&quot;&gt;python 比较&lt;/h2&gt;
&lt;p&gt;python 有三种读取文件的方法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;read() 会将所有内容读入到一个字符串中&lt;/li&gt;
&lt;li&gt;readline() 每次读取一行&lt;/li&gt;
&lt;li&gt;readlines() 将所有内容按行读取，返回一个列表，列表中每个元素是一个字符串，一个字符串是一行内容&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;所以从效率上讲， read() 和readlines()会比readline()高，但是同时对内存的要求也比较高，需要能一次性将文件内容放入内存中。但是如果这个文件很大的话，就会影响到程序运行的速度，甚至会导致程序挂掉，此时分行读取或是设置buff_size会是个更好的选择&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-python&quot;&gt;#!/usr/bin/env python
import time
import os
def func1(source,dest):
    os.remove(dest)
    with open(source, &#39;r&#39;) as fr:
        content=fr.read()
    with open(dest,&#39;w&#39;) as fw:
        fw.write(content)
def  func2(source,dest):
    os.remove(dest)
    fw=open(dest,&#39;w&#39;)
    for line in open(source,&#39;r&#39;):
        fw.write(line)
    fw.close
if __name__ == &#39;__main__&#39;:
    from timeit import Timer
    t1=Timer(&quot;func1(&#39;log&#39;,&#39;log1&#39;)&quot;,&quot;from __main__ import func1&quot;)
    t2=Timer(&quot;func2(&#39;log&#39;,&#39;log1&#39;)&quot;,&quot;from __main__ import func2&quot;)
    print &quot;read once: &quot;+str(t1.timeit(1))
    print &quot;read line: &quot;+str(t2.timeit(1))
&lt;/pre&gt;
&lt;p&gt;40M文件5次处理时间：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;read once: 0.308089971542&lt;/p&gt;
&lt;p&gt;read line: 1.17492413521&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;1G文件首次处理时间：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;read once: 8.17146706581&lt;/p&gt;
&lt;p&gt;read line: 4.13687205315&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;1G文件5次处理时间：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;read once: 7.32681894302&lt;/p&gt;
&lt;p&gt;read line: 30.3610920906&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;有意思的是，虽然一次性读入内存效率比line by line读取的效率差，但是假如重复处理同一个文件，一次性读取的总体效率反而高，所以python应该做了类似于缓存的机制。所以当我们用python处理大文本文件的时候需要综合考虑服务器内存，文件处理次数来决定使用哪种方式。&lt;/p&gt;
</description>
        </item>
        
        <item>
            <title>python的两种计时方法</title>
            <link>Homepage link/articles/python-timeit.html?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=rss</link>
            <guid>Homepage link/articles/python-timeit.html</guid>
            <author>zxdy@vip.qq.com Ario</author>
            <pubDate>Tue, 13 Jan 2015 00:00:00 +0800</pubDate>
            <description>&lt;p&gt;其实我本意是就贴一段代码完事，但又觉得确实有点干巴巴，还是稍微灌点水吧。&lt;/p&gt;
&lt;p&gt;way1和way2分别代表了两种不同的计时方式，同时也展现了两种不同的用途。&lt;/p&gt;
&lt;p&gt;way1是使用了timeit包。Python 社区有句俗语：&quot;Python 自己带着电池。&quot; 别自己写计时框架。Python 2.7 具备一个叫做 timeit 的完美计时工具。看demo代码可以发现，它不仅支持对单个方法计时，还支持方法传参，更支持重复计时。我觉得这个计时方法更加适用于测试，特别是性能测试的时候。&lt;/p&gt;
&lt;p&gt;way2没什么好说的，一种很简单粗暴傻瓜化的计时方法，换种编程语言也是相同的套路。这个计时方法相比way1来说，更加浅显易懂，操作也简单，就是代码量相对较多，不够简洁。但它也不是没有市场，比较适合在python脚本中写日志。&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-python&quot;&gt;#!/usr/bin/env python
import time
from timeit import Timer
def func1(x):
    sum=0
    for i in  xrange(x*10000):
        sum=sum+i

def func2(x,y):
    sum=0
    for i in  xrange((x+y)*10000):
        sum=sum+i

if __name__ == &#39;__main__&#39;:
    #way1
    t1=Timer(&quot;func1(2)&quot;,&quot;from __main__ import func1&quot;)
    t2=Timer(&quot;func2(3,4)&quot;,&quot;from __main__ import func2&quot;)
    print(t1.timeit(1))
    print(t2.timeit(1))
    print(t1.repeat(4,10)) //第一个参数是重复整个测试的次数，第二个参数是每个测试中调用被计时语句的次数

    #way2
    start = time.clock()
    func1(2)
    elapsed = (time.clock() - start)
    print(&quot;Time used:&quot;, elapsed)
&lt;/pre&gt;
</description>
        </item>
        
        <item>
            <title>oracle 如何加快建立索引的速度</title>
            <link>Homepage link/articles/speed-up-create-index.html?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=rss</link>
            <guid>Homepage link/articles/speed-up-create-index.html</guid>
            <author>zxdy@vip.qq.com Ario</author>
            <pubDate>Fri, 19 Sep 2014 00:00:00 +0800</pubDate>
            <description>&lt;p&gt;通常情况下对oracle的表建立索引的时候并不需要考虑效率问题，这个通常情况指的是相应的表数据在百万级以下。但是一旦数据量大到千万级，亿级甚至更大的时候，我们就不能不考虑新建索引的效率问题，因为当表在建立索引的时候，会产生锁阻塞新数据的更新，如果索引不能很快地建立完毕，会对生产环境造成影响。&lt;/p&gt;
&lt;h1 id=&quot;1-pga设置&quot;&gt;1. PGA设置&lt;/h1&gt;
&lt;p&gt;hash_area_size： 这个参数控制每个会话的hash内存空间有多大。它也可以在会话级和实例级被修改。默认值是sort area空间大小的两倍
sort_area_size:  因为排序通常是在PGA中进行的，需要防止因空间或内存不足导致需要disk排序。&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-sql&quot;&gt;alter session set workarea_size_policy=manual;
alter session set hash_area_size=100000; 
alter session set sort_area_size=2000000000; -- 在系统可用内存足够的情况下，最大可以到2G
&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;question&lt;/em&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;什么是PGA&lt;/li&gt;
&lt;li&gt;什么是SGA&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;2-增加temp表空间&quot;&gt;2. 增加temp表空间&lt;/h1&gt;
&lt;p&gt;因为大表的数据量比较大，导致建索引时需要的temp表空间也比较大，一般来说接近索引的大小，没把握的情况下可以估算一下索引的大小先：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-sql&quot;&gt;set serveroutput on
declare  
 v_ddl varchar(1024);  
 v_used_bytes number;  
 v_alloc_bytes number;  
 begin  
 dbms_space.create_index_cost(  
 ddl =&gt;&#39; create index ids_t on user(userid)&#39;,used_bytes=&gt;v_used_bytes,alloc_bytes =&gt;v_alloc_bytes);  
 dbms_output.put_line(&#39;used_bytes=&#39;||v_used_bytes||&#39; bytes&#39;||&#39; alloc_bytes=&#39;|| v_alloc_bytes || &#39; bytes&#39;);  
 end;  
 /
&lt;/pre&gt;
&lt;p&gt;另外在建索引的过程中也可以随时监控表空间的使用情况，一旦发现temp表空间不够，可以随时加大&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-sql&quot;&gt;--查询表空间使用情况
SELECT UPPER(F.TABLESPACE_NAME) &quot;表空间名&quot;,
D.TOT_GROOTTE_MB &quot;表空间大小(M)&quot;,
D.TOT_GROOTTE_MB - F.TOTAL_BYTES &quot;已使用空间(M)&quot;,
TO_CHAR(ROUND((D.TOT_GROOTTE_MB - F.TOTAL_BYTES) / D.TOT_GROOTTE_MB * 100,2),&#39;990.99&#39;) &quot;使用比&quot;,
F.TOTAL_BYTES &quot;空闲空间(M)&quot;,
F.MAX_BYTES &quot;最大块(M)&quot;
FROM (SELECT TABLESPACE_NAME,
ROUND(SUM(BYTES) / (1024 * 1024), 2) TOTAL_BYTES,
ROUND(MAX(BYTES) / (1024 * 1024), 2) MAX_BYTES
FROM SYS.DBA_FREE_SPACE
GROUP BY TABLESPACE_NAME) F,
(SELECT DD.TABLESPACE_NAME,
ROUND(SUM(DD.BYTES) / (1024 * 1024), 2) TOT_GROOTTE_MB
FROM SYS.DBA_DATA_FILES DD
GROUP BY DD.TABLESPACE_NAME) D
WHERE D.TABLESPACE_NAME = F.TABLESPACE_NAME
ORDER BY 4 DESC;

select file_name,bytes/1024/1024 &quot;MB&quot;,autoextensible,tablespace_name from dba_temp_files;

--增加表空间大小
alter tablespace USERS add datafile &#39;/opt/ora9/users02.dbf&#39; size 50M autoextend on next 50M maxsize UNLIMITED;
&lt;/pre&gt;
&lt;h1 id=&quot;3-使用并行参数&quot;&gt;3. 使用并行参数&lt;/h1&gt;
&lt;p&gt;关于利用并行度创建索引，前提是多个CPU，单CPU下用并行度创建索引，可能会造成资源的争用。理论上来说8个CPU, 可以用parallel 6 ,最多占用6个CPU,另外留下两个CPU供其他进程使用。
查看CPU核数的方法有很多，详细见（oracle性能优化-CPU篇）。最简单地就是用下面这个sql直接查&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-sql&quot;&gt;SELECT * FROM v$osstat where stat_name=&#39;NUM_CPUS&#39;;
&lt;/pre&gt;
&lt;h1 id=&quot;4-使用nologging&quot;&gt;4. 使用nologging&lt;/h1&gt;
&lt;p&gt;nologging, 绝对应该使用，能减少大量redo log，使速度大幅上升。&lt;/p&gt;
&lt;p&gt;于是一个比较标准的并行nologging建索引语句就出炉了。对于生产环境，保险的办法是再加上online参数，避免建索引时的锁对dml产生阻塞。&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-sql&quot;&gt;CREATE INDEX  table_idx ON table (col )  NOLOGGING PARALLEL 6;
&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;Note&lt;/em&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;对于一个比较大的操作，oracle可能会有等待事件发生
首先可以通过sql developer查看等待时间的信息，得到等待时间的p1，p2，p3。然后通过下面的sql转换p1，p2得到具体等待的object。&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-sql&quot;&gt;select 
   owner,
   segment_name,
   segment_type
from 
   dba_extents
where 
   file_id = &amp;P1 and &amp;P2 between block_id and block_id + blocks -1;
&lt;/pre&gt;
&lt;/blockquote&gt;
</description>
        </item>
        
        <item>
            <title>AWR 启用和导出</title>
            <link>Homepage link/articles/extract-awr.html?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=rss</link>
            <guid>Homepage link/articles/extract-awr.html</guid>
            <author>zxdy@vip.qq.com Ario</author>
            <pubDate>Fri, 08 Aug 2014 00:00:00 +0800</pubDate>
            <description>&lt;h1 id=&quot;1．awr的启用&quot;&gt;1．AWR的启用&lt;/h1&gt;
&lt;p&gt;在默认情况下，Oracle启用数据库统计收集这项功能（即启用AWR）。是否启用AWR由初始化参数STATISTICS_LEVEL控制&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-sql&quot;&gt;SQL&gt; SHOW PARAMETER STATISTICS_LEVEL 
NAME                                 TYPE        VALUE
------------------------------------ ----------- ------------------------------
statistics_level                     string      TYPICAL
&lt;/pre&gt;
&lt;p&gt;如果STATISTICS_LEVEL的值为TYPICAL或者 ALL，表示启用AWR；如果STATISTICS_LEVEL的值为BASIC，表示禁用AWR。&lt;/p&gt;
&lt;p&gt;初始化参数statistics_level介绍：&lt;/p&gt;
&lt;p&gt;AWR的行为受到参数STATISTICS_LEVEL的影响。这个参数有三个值：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;BASIC：awr统计的计算和衍生值关闭.只收集少量的数据库统计信息.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;TYPICAL：默认值．只有部分的统计收集.他们代表需要的典型监控oracle数据库的行为.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;ALL : 所有可能的统计都被捕捉. 并且有操作系统的一些信息.这个级别的捕捉应该在很少的情况下,比如你要更多的sql诊断信息的时候才使用.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;2-导出awr报告&quot;&gt;2. 导出AWR报告&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;AWR比对报告&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&quot;prettyprint linenums lang-sql&quot;&gt;@$ORACLE_HOME/rdbms/admin/awrddrpt.sql
&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;RAC全局AWR&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&quot;prettyprint linenums lang-sql&quot;&gt;@$ORACLE_HOME/rdbms/admin/awrgrpt.sql
&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;本实例的AWR报告，运行脚本awrrpt.sql。&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&quot;prettyprint linenums lang-sql&quot;&gt;@$ORACLE_HOME/rdbms/admin/awrrpt.sql
&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;产生某个实例（RAC）的AWR报告，运行脚本awrrpti.sql。&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&quot;prettyprint linenums lang-sql&quot;&gt;@$ORACLE_HOME/rdbms/admin/awrrpti.sql
&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;产生某条SQL语句的AWR报告，运行脚本awrsqrpt.sql。&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&quot;prettyprint linenums lang-sql&quot;&gt;@$ORACLE_HOME/rdbms/admin/awrsqrpt.sql
&lt;/pre&gt;
</description>
        </item>
        
        <item>
            <title>为什么虚拟机+tor+vpn</title>
            <link>Homepage link/articles/why-vm-tor-and-vpn.html?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=rss</link>
            <guid>Homepage link/articles/why-vm-tor-and-vpn.html</guid>
            <author>zxdy@vip.qq.com Ario</author>
            <pubDate>Mon, 14 Apr 2014 00:00:00 +0800</pubDate>
            <description>&lt;h2 id=&quot;为啥要使用虚拟机&quot;&gt;为啥要使用虚拟机&lt;/h2&gt;
&lt;p&gt;使用虚拟机主要有俩原因。
第一个是为了好收拾，清理痕迹什么的。特别是MAC地址，系统指纹信息等等，这些一旦被收集到都可以作为呈堂证供。用虚拟机，干了坏事把快照恢复一下就好，省的清理cookie什么乱七八糟的，如果是干了特别坏的事那就把虚拟机删了，干净清透没问题～&lt;/p&gt;
&lt;p&gt;第二个原因是为了做网络隔离。直接连接网络很有可能会暴露你的公网ip地址。很显然在你的主机电脑上装了很多软件。。这些软件不说到底有没有后门，但是记录你的操作记录，或者某些隐私信息妥妥的，有些甚至可以直接绕过代理访问自己的服务器，一旦追查起来，都是很容易取证的。所以套一层虚拟机，搭一个干净的环境可以保护隐私不外泄。还有种双层虚拟机的，虚拟机A用作攻击机，虚拟机B用作网关，B必须是双网卡，一个host-only，一个NAT，然后A的所有信息先通过B中转到host再到公网。好吧，个人感觉这种真的是非常的蛋疼疼疼。。不过确实比单虚拟机更加安全。&lt;/p&gt;
&lt;h2 id=&quot;再说tor&quot;&gt;再说tor&lt;/h2&gt;
&lt;p&gt;这个具体干嘛的找谷歌吧，总的来说是一款专门设计用于隐匿上网身份的工具。为什么说它可以用来隐匿呢？咱们来看图
&lt;img src=&quot;http://zxdy-blog.qiniudn.com/tor.jpg&quot; alt=&quot;tor工作图&quot;&gt;&lt;/p&gt;
&lt;p&gt;tor在全世界有很多的中继节点，就是图中的2部分。当你启动tor用来上网的时候，首先经过1进入中继节点，TOR 客户端会随机挑选三个节点用于中转，并且每过几分钟会重新选择。中继节点分入口节点，中间节点，出口节点，然后再经过3到服务器。在这三步中，1和2都是经过加密的，只有在出口节点能看到你的真实访问信息。如果你访问的是https协议的网站，那就相对安全，因为https是加密的。如果访问的是http协议的网站，那么风险就比较大，因为出口节点说不定是蜜罐，在嗅探你的出口明文信息。但是由于1，2部分中间也都是加密传输，即便出口节点知道有人访问了某网站干了点啥，它也无法定位到来源的ip，除非所有节点都是蜜罐，或者有传说中NSA那样牛逼的破解密钥的能力一路追上来锁定你。&lt;/p&gt;
&lt;h2 id=&quot;还有vpn&quot;&gt;还有vpn&lt;/h2&gt;
&lt;p&gt;所以为啥还要用vpn啊？用tor感觉已经很安全了啊，即便是侧漏了好像也找不到自己也？&lt;/p&gt;
&lt;p&gt;感谢国家。。感谢GFW。。tor这种看上去一点都不像是五好青年用的东西必须肯定是分分钟在GFW的黑名单上啊。。。当你很嗨皮的启动tor想要体验一把“偷偷的上网，打枪地不要”时候，你会发现拓麻一个中继节点都连接不上啊～所以先整个VPN把自己翻出墙吧，然后才能连上tor。&lt;/p&gt;
&lt;h2 id=&quot;最后&quot;&gt;最后&lt;/h2&gt;
&lt;p&gt;警察蜀黍说，莫伸手，伸手必被抓。
这世上没有绝对的安全，丝绸之路创始人用tor如此high，还不是进去了。&lt;/p&gt;
</description>
        </item>
        
        <item>
            <title>oracle 存储过程显示异常行</title>
            <link>Homepage link/articles/locate-exception-line.html?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=rss</link>
            <guid>Homepage link/articles/locate-exception-line.html</guid>
            <author>zxdy@vip.qq.com Ario</author>
            <pubDate>Wed, 18 Dec 2013 00:00:00 +0800</pubDate>
            <description>&lt;p&gt;记一个写pl/sql比较有用的技巧。当oracle的存储过程运行出现异常的时候，虽然可以被exception抓到，但是无法定位究竟是在之前的业务处理逻辑代码哪一行出现了问题，调试起来不方便。比如下面的demo运行之后&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-pl/sql&quot;&gt;CREATE OR REPLACE
  FUNCTION FUNC
    RETURN NUMBER
  AS
    v_in NUMBER;
    v_out NUMBER;

  BEGIN
    v_in :=12;
    dbms_output.put_line(v_in);
    v_out:=v_in/0;
    RETURN v_out;
  EXCEPTION
  WHEN OTHERS THEN
    dbms_output.put_line(&#39;######exception:&#39;);
  END FUNC;
&lt;/pre&gt;
&lt;p&gt;显示的结果如下，并没有显示真正异常的代码行号&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-text&quot;&gt;Connecting to the database dev74.
ORA-06503: PL/SQL: Function returned without value
ORA-06512: at &quot;TLSPID.FUNC&quot;, line 16
ORA-06512: at line 5
12
######exception:
Process exited.
Disconnecting from the database dev74.
&lt;/pre&gt;
&lt;p&gt;但是只要在exception代码块中加上第16行的代码&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-pl/sql&quot;&gt;CREATE OR REPLACE
  FUNCTION FUNC
    RETURN NUMBER
  AS
    v_in NUMBER;
    v_out NUMBER;

  BEGIN
    v_in :=12;
    dbms_output.put_line(v_in);
    v_out:=v_in/0;
    RETURN v_out;
  EXCEPTION
  WHEN OTHERS THEN
    dbms_output.put_line(&#39;######exception:&#39;);
    dbms_output.put_line(dbms_utility.format_error_backtrace());
  END FUNC;
&lt;/pre&gt;
&lt;p&gt;运行后结果如下，可以看到第7行显示了出错的地方。实际使用的时候注意出错的行号应该是报错的下一行。比如下面显示第10行报错，但实际应该是第11行出错。&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-text&quot;&gt;Connecting to the database dev74.
ORA-06503: PL/SQL: Function returned without value
ORA-06512: at &quot;TLSPID.FUNC&quot;, line 16
ORA-06512: at line 5
12
######exception:
ORA-06512: at &quot;TLSPID.FUNC&quot;, line 10
Process exited.
Disconnecting from the database dev74.
&lt;/pre&gt;
</description>
        </item>
        
        <item>
            <title>sql developer怎样调试Pipelined</title>
            <link>Homepage link/articles/debug-Pipelined.html?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=rss</link>
            <guid>Homepage link/articles/debug-Pipelined.html</guid>
            <author>zxdy@vip.qq.com Ario</author>
            <pubDate>Wed, 18 Dec 2013 00:00:00 +0800</pubDate>
            <description>&lt;p&gt;在sql developer中，如果直接对pipelined语句进行断点debug会报错，那么怎样可以解决这个问题呢？可以用procedure包住这个函数，再进行单步调试。下面是演示的demo。  &lt;/p&gt;
&lt;h2 id=&quot;准备pipelined&quot;&gt;准备pipelined&lt;/h2&gt;
&lt;pre class=&quot;prettyprint linenums lang-pl/sql&quot;&gt;CREATE TYPE t_tf_row AS OBJECT (
  id           NUMBER,
  description  VARCHAR2(50)
);
/

CREATE TYPE t_tf_tab IS TABLE OF t_tf_row;
/

CREATE OR REPLACE FUNCTION get_tab_ptf (p_rows IN NUMBER) RETURN t_tf_tab PIPELINED AS
BEGIN
  FOR i IN 1 .. p_rows LOOP
    PIPE ROW(t_tf_row(i, &#39;Description for &#39; || i));   
  END LOOP;

  RETURN;
END;
/
&lt;/pre&gt;
&lt;h2 id=&quot;然后用procedure包住这个get_tab_ptf函数&quot;&gt;然后用procedure包住这个get_tab_ptf函数&lt;/h2&gt;
&lt;pre class=&quot;prettyprint linenums lang-pl/sql&quot;&gt;CREATE OR REPLACE
PROCEDURE test_pipeline
IS
BEGIN
  FOR cur_rec IN (SELECT *  FROM  TABLE(get_tab_ptf(10)))
  LOOP
    dbms_output.put_line(&#39;get one row!&#39;);
  END LOOP;
END;
&lt;/pre&gt;
&lt;h2 id=&quot;断点位置&quot;&gt;断点位置&lt;/h2&gt;
&lt;p&gt;最后将断点打在test_pipeline的for循环上，对这个procedure进行单步调试就可以跳转到函数get_tab_ptf内部了。&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
