<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>RSS feed title</title>
        <link>Homepage link</link>
        <description>RSS feed description</description>
        <lastBuildDate>Thu, 12 Mar 2015 20:11:47 +0800</lastBuildDate>
        <language>zh-cn</language>
        
        <item>
            <title>oracle性能优化-CPU篇(上)</title>
            <link>Homepage link/articles/oracle-tunning-cpu-1.html?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=rss</link>
            <guid>Homepage link/articles/oracle-tunning-cpu-1.html</guid>
            <author>zxdy@vip.qq.com Ario</author>
            <pubDate>Wed, 04 Mar 2015 00:00:00 +0800</pubDate>
            <description>&lt;p&gt;在任何一样计算机软件产品中，当我们需要考虑其性能的时候，往往都会从CPU，IO，Network这三个方面考虑。CPU代表着处理问题的能力，IO代表着存储的吞吐能力，Network代表着数据传输的能力。oracle当然也不例外。&lt;/p&gt;
&lt;p&gt;下图反映的是一个应用程序总体的响应时间的分布情况。用户在前端发出数据的请求之后，经过网络层，到达数据库服务器。数据库服务器接收请求，然后对SQL进行语法语义分析，然后生成执行计划，接着执行sql，取得数据最后再次经过网络层返回到前端展现给用户。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://zxdy-blog.qiniudn.com/bottle-neck-of-oracle.png&quot; alt=&quot;bottle-neck-of-oracle&quot;&gt;&lt;/p&gt;
&lt;p&gt;很显然 &lt;strong&gt;oracle的处理时间=cpu处理时间+[资源等待时间+Disk IO 等待时间]&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;根据以上公式，我们可以发现只要能有效地利用cpu资源和降低等待时间就可以提高数据库的性能，使它处理得更快。&lt;/p&gt;
&lt;p&gt;这篇文章主要关注oracle sql在cpu上的性能优化。个人感觉相比等待上的优化简单一些，等待很多时候涉及到并发，资源争用，数据块等知识，优化也更加复杂不好下手。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;那么问题来了：&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;1-首先，怎么查看cpu信息&quot;&gt;1. 首先，怎么查看CPU信息&lt;/h2&gt;
&lt;p&gt;CPU的多少在很大程度上（质量也是很重要滴）决定了数据库性能的好坏。越多的CPU，可以并发的数目就越多。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;用系统命令查看。这里我默认认为oracle是安装在linux服务器上，当然装在windows上的不是没有，只是略奇葩了。&lt;/p&gt;
&lt;p&gt;  refer to  &lt;a href=&quot;http://zxdy.github.io/articles/linux-info-check.html&quot;&gt;查看cpu信息&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;sql查询NUM_CPUS字段。v$osstat这张表包含了很多有用的信息
附上&lt;a href=&quot;http://docs.oracle.com/cd/E11882_01/server.112/e40402/dynviews_2085.htm#REFRN30321&quot;&gt;官方文档&lt;/a&gt;解释&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&quot;prettyprint linenums lang-sql&quot;&gt;SELECT * FROM v$osstat;
&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;awr报告。在awr中会有cpu相关的各种报告，包括硬件信息以及更重要的性能信息。关于cpu的性能分析我会在后面展开。下面这张图展现了当前实例使用的cpu硬件信息。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;http://zxdy-blog.qiniudn.com/awr_cpu.png&quot; alt=&quot;awr cpu&quot;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;CPUs: 逻辑cpu数
Cores: cpu核数
Sockets: 物理cpu数&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;2-怎么看cpu的性能&quot;&gt;2. 怎么看CPU的性能&lt;/h2&gt;
&lt;p&gt;上面的CPU硬件信息只是帮助我们有个初步的概念，如果说你的数据库性能很差，CPU又很烂，很烂还没几个，那你真的该先换CPU了。。&lt;/p&gt;
&lt;p&gt;换完CPU，我们先来了解下下面这两个概念：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;host cpu&lt;/li&gt;
&lt;li&gt;instance cpu&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在AWR报告中会有这样两个不同的分类，像是这样&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://zxdy-blog.qiniudn.com/awr_cpu.png&quot; alt=&quot;host cpu&quot;&gt;&lt;/p&gt;
&lt;p&gt;还有这样&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://zxdy-blog.qiniudn.com/instance_cpu.png&quot; alt=&quot;instance cpu&quot;&gt;&lt;/p&gt;
&lt;p&gt;它们其实是分别代表了服务器cpu的负载和oracle实例的负载情况。&lt;/p&gt;
&lt;p&gt;对于host cpu：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&quot;Load Average&quot; begin/end值代表CPU的大致运行队列大小。上图中快照开始
到结束，平均 CPU负载减少了。&lt;/li&gt;
&lt;li&gt;%User+%System=&gt; 总的CPU使用率，在这里是5.7%。&lt;/li&gt;
&lt;li&gt;Busy Time=Elapsed Time * NUM_CPUS * CPU utilization&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对于instance cpu:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;%Total CPU,该实例所使用的CPU占总CPU的比例 -&gt; % of total CPU for
Instance&lt;/li&gt;
&lt;li&gt;%Busy CPU，该实例所使用的Cpu占总的被使用CPU的比例 -&gt; % of busy CPU for Instance。例如共4个逻辑CPU，其中3个被完全使用， 3个中的1 个完全被该实例使用，则%Total CPU= 1/4 =25%，而%Busy CPU= 1/3= 33%&lt;/li&gt;
&lt;li&gt;当CPU高时一般看%Busy CPU可以确定CPU到底是否是本实例消耗的，还是
主机上其他程序。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;身为一个开发我还要时不时看awr报告也是蛮拼的。一般来讲，awr更多的是展现数据库整体上的性能分析，你可能在以上的host cpu以及instance cpu上发现cpu的负载很高，但这又有什么用呢？是不是觉得没法继续了呢？当然不是，awr还提供了更多的详细的报告帮助我们定位哪些sql的cpu占用比较厉害：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;AWR SQL ordered by Elapsed Time：&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;http://zxdy-blog.qiniudn.com/sql_order_by_elapsed_time.png&quot; alt=&quot;AWR SQL ordered by Elapsed Time&quot;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;%CPU - CPU Time as a percentage of Elapsed Time -&gt; 这个语句耗费的DB TIME里CPU TIME占多少比例 -&gt; 这个语句是否是CPU敏感的&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;2.AWR SQL ordered by CPU Time：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://zxdy-blog.qiniudn.com/sql_order_by_cpu_time.png&quot; alt=&quot;AWR SQL order by cpu time&quot;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;第一列CPU TIME统计这个sql总共在快照时间内总共花费的cpu时间，在这个值比较高的情况下，如果相应的%CPU值也很高， 说明这个sql在cpu上的负载很高，需要考虑优化。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;如果发现有比较突出的sql，很可能就是瓶颈所在，可以继续跑个@?/rdbms/admin/awrsqrpt.sql看看&lt;/strong&gt;&lt;/p&gt;
</description>
        </item>
        
        <item>
            <title>大文件读写效率比较</title>
            <link>Homepage link/articles/file-read-write-compare.html?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=rss</link>
            <guid>Homepage link/articles/file-read-write-compare.html</guid>
            <author>zxdy@vip.qq.com Ario</author>
            <pubDate>Thu, 15 Jan 2015 00:00:00 +0800</pubDate>
            <description>&lt;p&gt;之前做到一个大日志文件（size &gt; 1G）解析的项目，在此记录下对于大文本解析方式的效率比较。不同方式的性能差别很大，那个项目的日志解析时间能从原来的超过36小时优化到只需要2分钟，awk功不可没。&lt;/p&gt;
&lt;h2 id=&quot;bash-比较&quot;&gt;bash 比较&lt;/h2&gt;
&lt;p&gt;bash脚本中对于文本的读取主要有以下四种，尽管 AWK 具有完全属于其本身的语法，但在此我也把它归在一起：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-bash&quot;&gt;#方法一
func1(){
    rm -f $2
    echo &quot;$(date) start to read&quot;
    start_time=$(date +%s)
    cat $1|while read Line
    do
        echo $Line &gt;&gt; $2
    done
    end_time=$(date +%s)
    echo &quot;$(date) end to read&quot;
    echo &quot;cost: &quot;$((end_time-start_time))&quot;sec&quot;
}

#方法二
func2(){
    rm -f $2
    echo &quot;$(date) start to read&quot;
    start_time=$(date +%s)
    while read Line
    do
        echo $Line &gt;&gt; $2
    done &lt;$1
    end_time=$(date +%s)
    echo &quot;$(date) end to read&quot;
    echo &quot;cost: &quot;$((end_time-start_time))&quot;sec&quot;
}

#方法三
func3(){
    rm -f $2
    echo &quot;$(date) start to read&quot;
    start_time=$(date +%s)
    for Line in `cat $1`
    do
        echo $Line &gt;&gt; $2
    done
    end_time=$(date +%s)
    echo &quot;$(date) end to read&quot;
    echo &quot;cost: &quot;$((end_time-start_time))&quot;sec&quot;
}

#func4
func4(){
    rm -f $2
    echo &quot;$(date) start to read&quot;
    start_time=$(date +%s)
    awk &#39;{print $0}&#39; $1 &gt; $2
    echo &quot;$(date) end to read&quot;
    echo &quot;cost: &quot;$((end_time-start_time))&quot;sec&quot;
}


source=$1
dest=$2

#比较结果：
echo &quot;####cat read: &quot;
func1 $source $dest
echo &quot;####redirect read: &quot;
func2 $source $dest
echo &quot;####for read: &quot;
func3 $source $dest
echo &quot;####awk read: &quot;
func4 $source $dest
&lt;/pre&gt;
&lt;p&gt;结果:&lt;/p&gt;
&lt;p&gt;cat read:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Thu Jan 15 07:57:50 GMT 2015 start to read&lt;/p&gt;
&lt;p&gt;Thu Jan 15 07:58:33 GMT 2015 end to read&lt;/p&gt;
&lt;p&gt;cost: 43sec&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;redirect read:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Thu Jan 15 07:58:33 GMT 2015 start to read&lt;/p&gt;
&lt;p&gt;Thu Jan 15 07:59:01 GMT 2015 end to read&lt;/p&gt;
&lt;p&gt;cost: 28sec&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;for read:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Thu Jan 15 07:59:01 GMT 2015 start to read&lt;/p&gt;
&lt;p&gt;Thu Jan 15 08:00:00 GMT 2015 end to read&lt;/p&gt;
&lt;p&gt;cost: 59sec&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;awk read:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Thu Jan 15 08:00:00 GMT 2015 start to read&lt;/p&gt;
&lt;p&gt;Thu Jan 15 08:00:00 GMT 2015 end to read&lt;/p&gt;
&lt;p&gt;cost: 0sec&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;从以上结果可以看出，awk的效率远超其他方法&lt;/p&gt;
&lt;h2 id=&quot;python-比较&quot;&gt;python 比较&lt;/h2&gt;
&lt;p&gt;python 有三种读取文件的方法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;read() 会将所有内容读入到一个字符串中&lt;/li&gt;
&lt;li&gt;readline() 每次读取一行&lt;/li&gt;
&lt;li&gt;readlines() 将所有内容按行读取，返回一个列表，列表中每个元素是一个字符串，一个字符串是一行内容&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;所以从效率上讲， read() 和readlines()会比readline()高，但是同时对内存的要求也比较高，需要能一次性将文件内容放入内存中。但是如果这个文件很大的话，就会影响到程序运行的速度，甚至会导致程序挂掉，此时分行读取或是设置buff_size会是个更好的选择&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-python&quot;&gt;#!/usr/bin/env python
import time
import os
def func1(source,dest):
    os.remove(dest)
    with open(source, &#39;r&#39;) as fr:
        content=fr.read()
    with open(dest,&#39;w&#39;) as fw:
        fw.write(content)
def  func2(source,dest):
    os.remove(dest)
    fw=open(dest,&#39;w&#39;)
    for line in open(source,&#39;r&#39;):
        fw.write(line)
    fw.close
if __name__ == &#39;__main__&#39;:
    from timeit import Timer
    t1=Timer(&quot;func1(&#39;log&#39;,&#39;log1&#39;)&quot;,&quot;from __main__ import func1&quot;)
    t2=Timer(&quot;func2(&#39;log&#39;,&#39;log1&#39;)&quot;,&quot;from __main__ import func2&quot;)
    print &quot;read once: &quot;+str(t1.timeit(1))
    print &quot;read line: &quot;+str(t2.timeit(1))
&lt;/pre&gt;
&lt;p&gt;40M文件5次处理时间：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;read once: 0.308089971542&lt;/p&gt;
&lt;p&gt;read line: 1.17492413521&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;1G文件首次处理时间：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;read once: 8.17146706581&lt;/p&gt;
&lt;p&gt;read line: 4.13687205315&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;1G文件5次处理时间：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;read once: 7.32681894302&lt;/p&gt;
&lt;p&gt;read line: 30.3610920906&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;有意思的是，虽然一次性读入内存效率比line by line读取的效率差，但是假如重复处理同一个文件，一次性读取的总体效率反而高，所以python应该做了类似于缓存的机制。所以当我们用python处理大文本文件的时候需要综合考虑服务器内存，文件处理次数来决定使用哪种方式。&lt;/p&gt;
</description>
        </item>
        
        <item>
            <title>python的两种计时方法</title>
            <link>Homepage link/articles/python-timeit.html?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=rss</link>
            <guid>Homepage link/articles/python-timeit.html</guid>
            <author>zxdy@vip.qq.com Ario</author>
            <pubDate>Tue, 13 Jan 2015 00:00:00 +0800</pubDate>
            <description>&lt;p&gt;其实我本意是就贴一段代码完事，但又觉得确实有点干巴巴，还是稍微灌点水吧。&lt;/p&gt;
&lt;p&gt;way1和way2分别代表了两种不同的计时方式，同时也展现了两种不同的用途。&lt;/p&gt;
&lt;p&gt;way1是使用了timeit包。Python 社区有句俗语：&quot;Python 自己带着电池。&quot; 别自己写计时框架。Python 2.7 具备一个叫做 timeit 的完美计时工具。看demo代码可以发现，它不仅支持对单个方法计时，还支持方法传参，更支持重复计时。我觉得这个计时方法更加适用于测试，特别是性能测试的时候。&lt;/p&gt;
&lt;p&gt;way2没什么好说的，一种很简单粗暴傻瓜化的计时方法，换种编程语言也是相同的套路。这个计时方法相比way1来说，更加浅显易懂，操作也简单，就是代码量相对较多，不够简洁。但它也不是没有市场，比较适合在python脚本中写日志。&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-python&quot;&gt;#!/usr/bin/env python
import time
from timeit import Timer
def func1(x):
    sum=0
    for i in  xrange(x*10000):
        sum=sum+i

def func2(x,y):
    sum=0
    for i in  xrange((x+y)*10000):
        sum=sum+i

if __name__ == &#39;__main__&#39;:
    #way1
    t1=Timer(&quot;func1(2)&quot;,&quot;from __main__ import func1&quot;)
    t2=Timer(&quot;func2(3,4)&quot;,&quot;from __main__ import func2&quot;)
    print(t1.timeit(1))
    print(t2.timeit(1))
    print(t1.repeat(4,10)) //第一个参数是重复整个测试的次数，第二个参数是每个测试中调用被计时语句的次数

    #way2
    start = time.clock()
    func1(2)
    elapsed = (time.clock() - start)
    print(&quot;Time used:&quot;, elapsed)
&lt;/pre&gt;
</description>
        </item>
        
        <item>
            <title>oracle 如何加快建立索引的速度</title>
            <link>Homepage link/articles/speed-up-create-index.html?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=rss</link>
            <guid>Homepage link/articles/speed-up-create-index.html</guid>
            <author>zxdy@vip.qq.com Ario</author>
            <pubDate>Fri, 19 Sep 2014 00:00:00 +0800</pubDate>
            <description>&lt;p&gt;通常情况下对oracle的表建立索引的时候并不需要考虑效率问题，这个通常情况指的是相应的表数据在百万级以下。但是一旦数据量大到千万级，亿级甚至更大的时候，我们就不能不考虑新建索引的效率问题，因为当表在建立索引的时候，会产生锁阻塞新数据的更新，如果索引不能很快地建立完毕，会对生产环境造成影响。&lt;/p&gt;
&lt;h1 id=&quot;1-pga设置&quot;&gt;1. PGA设置&lt;/h1&gt;
&lt;p&gt;hash_area_size： 这个参数控制每个会话的hash内存空间有多大。它也可以在会话级和实例级被修改。默认值是sort area空间大小的两倍
sort_area_size:  因为排序通常是在PGA中进行的，需要防止因空间或内存不足导致需要disk排序。&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-sql&quot;&gt;alter session set workarea_size_policy=manual;
alter session set hash_area_size=100000; 
alter session set sort_area_size=2000000000; -- 在系统可用内存足够的情况下，最大可以到2G
&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;question&lt;/em&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;什么是PGA&lt;/li&gt;
&lt;li&gt;什么是SGA&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;2-增加temp表空间&quot;&gt;2. 增加temp表空间&lt;/h1&gt;
&lt;p&gt;因为大表的数据量比较大，导致建索引时需要的temp表空间也比较大，一般来说接近索引的大小，没把握的情况下可以估算一下索引的大小先：&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-sql&quot;&gt;set serveroutput on
declare  
 v_ddl varchar(1024);  
 v_used_bytes number;  
 v_alloc_bytes number;  
 begin  
 dbms_space.create_index_cost(  
 ddl =&gt;&#39; create index ids_t on user(userid)&#39;,used_bytes=&gt;v_used_bytes,alloc_bytes =&gt;v_alloc_bytes);  
 dbms_output.put_line(&#39;used_bytes=&#39;||v_used_bytes||&#39; bytes&#39;||&#39; alloc_bytes=&#39;|| v_alloc_bytes || &#39; bytes&#39;);  
 end;  
 /
&lt;/pre&gt;
&lt;p&gt;另外在建索引的过程中也可以随时监控表空间的使用情况，一旦发现temp表空间不够，可以随时加大&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-sql&quot;&gt;--查询表空间使用情况
SELECT UPPER(F.TABLESPACE_NAME) &quot;表空间名&quot;,
D.TOT_GROOTTE_MB &quot;表空间大小(M)&quot;,
D.TOT_GROOTTE_MB - F.TOTAL_BYTES &quot;已使用空间(M)&quot;,
TO_CHAR(ROUND((D.TOT_GROOTTE_MB - F.TOTAL_BYTES) / D.TOT_GROOTTE_MB * 100,2),&#39;990.99&#39;) &quot;使用比&quot;,
F.TOTAL_BYTES &quot;空闲空间(M)&quot;,
F.MAX_BYTES &quot;最大块(M)&quot;
FROM (SELECT TABLESPACE_NAME,
ROUND(SUM(BYTES) / (1024 * 1024), 2) TOTAL_BYTES,
ROUND(MAX(BYTES) / (1024 * 1024), 2) MAX_BYTES
FROM SYS.DBA_FREE_SPACE
GROUP BY TABLESPACE_NAME) F,
(SELECT DD.TABLESPACE_NAME,
ROUND(SUM(DD.BYTES) / (1024 * 1024), 2) TOT_GROOTTE_MB
FROM SYS.DBA_DATA_FILES DD
GROUP BY DD.TABLESPACE_NAME) D
WHERE D.TABLESPACE_NAME = F.TABLESPACE_NAME
ORDER BY 4 DESC;

select file_name,bytes/1024/1024 &quot;MB&quot;,autoextensible,tablespace_name from dba_temp_files;

--增加表空间大小
alter tablespace USERS add datafile &#39;/opt/ora9/users02.dbf&#39; size 50M autoextend on next 50M maxsize UNLIMITED;
&lt;/pre&gt;
&lt;h1 id=&quot;3-使用并行参数&quot;&gt;3. 使用并行参数&lt;/h1&gt;
&lt;p&gt;关于利用并行度创建索引，前提是多个CPU，单CPU下用并行度创建索引，可能会造成资源的争用。理论上来说8个CPU, 可以用parallel 6 ,最多占用6个CPU,另外留下两个CPU供其他进程使用。
查看CPU核数的方法有很多，详细见（oracle性能优化-CPU篇）。最简单地就是用下面这个sql直接查&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-sql&quot;&gt;SELECT * FROM v$osstat where stat_name=&#39;NUM_CPUS&#39;;
&lt;/pre&gt;
&lt;h1 id=&quot;4-使用nologging&quot;&gt;4. 使用nologging&lt;/h1&gt;
&lt;p&gt;nologging, 绝对应该使用，能减少大量redo log，使速度大幅上升。&lt;/p&gt;
&lt;p&gt;于是一个比较标准的并行nologging建索引语句就出炉了。对于生产环境，保险的办法是再加上online参数，避免建索引时的锁对dml产生阻塞。&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-sql&quot;&gt;CREATE INDEX  table_idx ON table (col )  NOLOGGING PARALLEL 6;
&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;Note&lt;/em&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;对于一个比较大的操作，oracle可能会有等待事件发生
首先可以通过sql developer查看等待时间的信息，得到等待时间的p1，p2，p3。然后通过下面的sql转换p1，p2得到具体等待的object。&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-sql&quot;&gt;select 
   owner,
   segment_name,
   segment_type
from 
   dba_extents
where 
   file_id = &amp;P1 and &amp;P2 between block_id and block_id + blocks -1;
&lt;/pre&gt;
&lt;/blockquote&gt;
</description>
        </item>
        
        <item>
            <title>AWR 启用和导出</title>
            <link>Homepage link/articles/extract-awr.html?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=rss</link>
            <guid>Homepage link/articles/extract-awr.html</guid>
            <author>zxdy@vip.qq.com Ario</author>
            <pubDate>Fri, 08 Aug 2014 00:00:00 +0800</pubDate>
            <description>&lt;h1 id=&quot;1．awr的启用&quot;&gt;1．AWR的启用&lt;/h1&gt;
&lt;p&gt;在默认情况下，Oracle启用数据库统计收集这项功能（即启用AWR）。是否启用AWR由初始化参数STATISTICS_LEVEL控制&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-sql&quot;&gt;SQL&gt; SHOW PARAMETER STATISTICS_LEVEL 
NAME                                 TYPE        VALUE
------------------------------------ ----------- ------------------------------
statistics_level                     string      TYPICAL
&lt;/pre&gt;
&lt;p&gt;如果STATISTICS_LEVEL的值为TYPICAL或者 ALL，表示启用AWR；如果STATISTICS_LEVEL的值为BASIC，表示禁用AWR。&lt;/p&gt;
&lt;p&gt;初始化参数statistics_level介绍：&lt;/p&gt;
&lt;p&gt;AWR的行为受到参数STATISTICS_LEVEL的影响。这个参数有三个值：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;BASIC：awr统计的计算和衍生值关闭.只收集少量的数据库统计信息.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;TYPICAL：默认值．只有部分的统计收集.他们代表需要的典型监控oracle数据库的行为.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;ALL : 所有可能的统计都被捕捉. 并且有操作系统的一些信息.这个级别的捕捉应该在很少的情况下,比如你要更多的sql诊断信息的时候才使用.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;2-导出awr报告&quot;&gt;2. 导出AWR报告&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;AWR比对报告&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&quot;prettyprint linenums lang-sql&quot;&gt;@$ORACLE_HOME/rdbms/admin/awrddrpt.sql
&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;RAC全局AWR&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&quot;prettyprint linenums lang-sql&quot;&gt;@$ORACLE_HOME/rdbms/admin/awrgrpt.sql
&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;本实例的AWR报告，运行脚本awrrpt.sql。&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&quot;prettyprint linenums lang-sql&quot;&gt;@$ORACLE_HOME/rdbms/admin/awrrpt.sql
&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;产生某个实例（RAC）的AWR报告，运行脚本awrrpti.sql。&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&quot;prettyprint linenums lang-sql&quot;&gt;@$ORACLE_HOME/rdbms/admin/awrrpti.sql
&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;产生某条SQL语句的AWR报告，运行脚本awrsqrpt.sql。&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&quot;prettyprint linenums lang-sql&quot;&gt;@$ORACLE_HOME/rdbms/admin/awrsqrpt.sql
&lt;/pre&gt;
</description>
        </item>
        
        <item>
            <title>为什么虚拟机+tor+vpn</title>
            <link>Homepage link/articles/why-vm-tor-and-vpn.html?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=rss</link>
            <guid>Homepage link/articles/why-vm-tor-and-vpn.html</guid>
            <author>zxdy@vip.qq.com Ario</author>
            <pubDate>Mon, 14 Apr 2014 00:00:00 +0800</pubDate>
            <description>&lt;h2 id=&quot;为啥要使用虚拟机&quot;&gt;为啥要使用虚拟机&lt;/h2&gt;
&lt;p&gt;使用虚拟机主要有俩原因。
第一个是为了好收拾，清理痕迹什么的。特别是MAC地址，系统指纹信息等等，这些一旦被收集到都可以作为呈堂证供。用虚拟机，干了坏事把快照恢复一下就好，省的清理cookie什么乱七八糟的，如果是干了特别坏的事那就把虚拟机删了，干净清透没问题～&lt;/p&gt;
&lt;p&gt;第二个原因是为了做网络隔离。直接连接网络很有可能会暴露你的公网ip地址。很显然在你的主机电脑上装了很多软件。。这些软件不说到底有没有后门，但是记录你的操作记录，或者某些隐私信息妥妥的，有些甚至可以直接绕过代理访问自己的服务器，一旦追查起来，都是很容易取证的。所以套一层虚拟机，搭一个干净的环境可以保护隐私不外泄。还有种双层虚拟机的，虚拟机A用作攻击机，虚拟机B用作网关，B必须是双网卡，一个host-only，一个NAT，然后A的所有信息先通过B中转到host再到公网。好吧，个人感觉这种真的是非常的蛋疼疼疼。。不过确实比单虚拟机更加安全。&lt;/p&gt;
&lt;h2 id=&quot;再说tor&quot;&gt;再说tor&lt;/h2&gt;
&lt;p&gt;这个具体干嘛的找谷歌吧，总的来说是一款专门设计用于隐匿上网身份的工具。为什么说它可以用来隐匿呢？咱们来看图
&lt;img src=&quot;http://zxdy-blog.qiniudn.com/tor.jpg&quot; alt=&quot;tor工作图&quot;&gt;&lt;/p&gt;
&lt;p&gt;tor在全世界有很多的中继节点，就是图中的2部分。当你启动tor用来上网的时候，首先经过1进入中继节点，TOR 客户端会随机挑选三个节点用于中转，并且每过几分钟会重新选择。中继节点分入口节点，中间节点，出口节点，然后再经过3到服务器。在这三步中，1和2都是经过加密的，只有在出口节点能看到你的真实访问信息。如果你访问的是https协议的网站，那就相对安全，因为https是加密的。如果访问的是http协议的网站，那么风险就比较大，因为出口节点说不定是蜜罐，在嗅探你的出口明文信息。但是由于1，2部分中间也都是加密传输，即便出口节点知道有人访问了某网站干了点啥，它也无法定位到来源的ip，除非所有节点都是蜜罐，或者有传说中NSA那样牛逼的破解密钥的能力一路追上来锁定你。&lt;/p&gt;
&lt;h2 id=&quot;还有vpn&quot;&gt;还有vpn&lt;/h2&gt;
&lt;p&gt;所以为啥还要用vpn啊？用tor感觉已经很安全了啊，即便是侧漏了好像也找不到自己也？&lt;/p&gt;
&lt;p&gt;感谢国家。。感谢GFW。。tor这种看上去一点都不像是五好青年用的东西必须肯定是分分钟在GFW的黑名单上啊。。。当你很嗨皮的启动tor想要体验一把“偷偷的上网，打枪地不要”时候，你会发现拓麻一个中继节点都连接不上啊～所以先整个VPN把自己翻出墙吧，然后才能连上tor。&lt;/p&gt;
&lt;h2 id=&quot;最后&quot;&gt;最后&lt;/h2&gt;
&lt;p&gt;警察蜀黍说，莫伸手，伸手必被抓。
这世上没有绝对的安全，丝绸之路创始人用tor如此high，还不是进去了。&lt;/p&gt;
</description>
        </item>
        
        <item>
            <title>oracle 存储过程显示异常行</title>
            <link>Homepage link/articles/locate-exception-line.html?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=rss</link>
            <guid>Homepage link/articles/locate-exception-line.html</guid>
            <author>zxdy@vip.qq.com Ario</author>
            <pubDate>Wed, 18 Dec 2013 00:00:00 +0800</pubDate>
            <description>&lt;p&gt;记一个写pl/sql比较有用的技巧。当oracle的存储过程运行出现异常的时候，虽然可以被exception抓到，但是无法定位究竟是在之前的业务处理逻辑代码哪一行出现了问题，调试起来不方便。比如下面的demo运行之后&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-pl/sql&quot;&gt;CREATE OR REPLACE
  FUNCTION FUNC
    RETURN NUMBER
  AS
    v_in NUMBER;
    v_out NUMBER;

  BEGIN
    v_in :=12;
    dbms_output.put_line(v_in);
    v_out:=v_in/0;
    RETURN v_out;
  EXCEPTION
  WHEN OTHERS THEN
    dbms_output.put_line(&#39;######exception:&#39;);
  END FUNC;
&lt;/pre&gt;
&lt;p&gt;显示的结果如下，并没有显示真正异常的代码行号&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-text&quot;&gt;Connecting to the database dev74.
ORA-06503: PL/SQL: Function returned without value
ORA-06512: at &quot;TLSPID.FUNC&quot;, line 16
ORA-06512: at line 5
12
######exception:
Process exited.
Disconnecting from the database dev74.
&lt;/pre&gt;
&lt;p&gt;但是只要在exception代码块中加上第16行的代码&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-pl/sql&quot;&gt;CREATE OR REPLACE
  FUNCTION FUNC
    RETURN NUMBER
  AS
    v_in NUMBER;
    v_out NUMBER;

  BEGIN
    v_in :=12;
    dbms_output.put_line(v_in);
    v_out:=v_in/0;
    RETURN v_out;
  EXCEPTION
  WHEN OTHERS THEN
    dbms_output.put_line(&#39;######exception:&#39;);
    dbms_output.put_line(dbms_utility.format_error_backtrace());
  END FUNC;
&lt;/pre&gt;
&lt;p&gt;运行后结果如下，可以看到第7行显示了出错的地方。实际使用的时候注意出错的行号应该是报错的下一行。比如下面显示第10行报错，但实际应该是第11行出错。&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-text&quot;&gt;Connecting to the database dev74.
ORA-06503: PL/SQL: Function returned without value
ORA-06512: at &quot;TLSPID.FUNC&quot;, line 16
ORA-06512: at line 5
12
######exception:
ORA-06512: at &quot;TLSPID.FUNC&quot;, line 10
Process exited.
Disconnecting from the database dev74.
&lt;/pre&gt;
</description>
        </item>
        
        <item>
            <title>sql developer怎样调试Pipelined</title>
            <link>Homepage link/articles/debug-Pipelined.html?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=rss</link>
            <guid>Homepage link/articles/debug-Pipelined.html</guid>
            <author>zxdy@vip.qq.com Ario</author>
            <pubDate>Wed, 18 Dec 2013 00:00:00 +0800</pubDate>
            <description>&lt;p&gt;在sql developer中，如果直接对pipelined语句进行断点debug会报错，那么怎样可以解决这个问题呢？可以用procedure包住这个函数，再进行单步调试。下面是演示的demo。  &lt;/p&gt;
&lt;h2 id=&quot;准备pipelined&quot;&gt;准备pipelined&lt;/h2&gt;
&lt;pre class=&quot;prettyprint linenums lang-pl/sql&quot;&gt;CREATE TYPE t_tf_row AS OBJECT (
  id           NUMBER,
  description  VARCHAR2(50)
);
/

CREATE TYPE t_tf_tab IS TABLE OF t_tf_row;
/

CREATE OR REPLACE FUNCTION get_tab_ptf (p_rows IN NUMBER) RETURN t_tf_tab PIPELINED AS
BEGIN
  FOR i IN 1 .. p_rows LOOP
    PIPE ROW(t_tf_row(i, &#39;Description for &#39; || i));   
  END LOOP;

  RETURN;
END;
/
&lt;/pre&gt;
&lt;h2 id=&quot;然后用procedure包住这个get_tab_ptf函数&quot;&gt;然后用procedure包住这个get_tab_ptf函数&lt;/h2&gt;
&lt;pre class=&quot;prettyprint linenums lang-pl/sql&quot;&gt;CREATE OR REPLACE
PROCEDURE test_pipeline
IS
BEGIN
  FOR cur_rec IN (SELECT *  FROM  TABLE(get_tab_ptf(10)))
  LOOP
    dbms_output.put_line(&#39;get one row!&#39;);
  END LOOP;
END;
&lt;/pre&gt;
&lt;h2 id=&quot;断点位置&quot;&gt;断点位置&lt;/h2&gt;
&lt;p&gt;最后将断点打在test_pipeline的for循环上，对这个procedure进行单步调试就可以跳转到函数get_tab_ptf内部了。&lt;/p&gt;
</description>
        </item>
        
        <item>
            <title>oracle dbms_output 在java中输出</title>
            <link>Homepage link/articles/dbms_output-in-java-console.html?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=rss</link>
            <guid>Homepage link/articles/dbms_output-in-java-console.html</guid>
            <author>zxdy@vip.qq.com Ario</author>
            <pubDate>Fri, 13 Dec 2013 00:00:00 +0800</pubDate>
            <description>&lt;p&gt;有没有碰到过这种情况，当你的java程序连接oracle运行存储过程的时候，java控制台只是仅仅输出java程序的相关信息，
而存储过程中的dbms_output内容却没有办法显示？这样只能跑去sql developer 单独调试存储过程，而不能直接在eclipse
进行集成测试，出了问题也不好定位。  &lt;/p&gt;
&lt;p&gt;所以在此分享一个解决方案： &lt;a href=&quot;http://asktom.oracle.com/pls/asktom/f?p=100:11:0::::P11_QUESTION_ID:45027262935845&quot;&gt;原文链接&lt;/a&gt; 。05年的一个方法，不知现在有没有更好的：）  &lt;/p&gt;
&lt;h2 id=&quot;存储过程demo&quot;&gt;存储过程demo&lt;/h2&gt;
&lt;pre class=&quot;prettyprint linenums lang-pl/sql&quot;&gt;create or replace
PROCEDURE test_java_dbmsOutPut
IS
BEGIN
   dbms_output.put_line(&#39;im in store procedure&#39;);
END;
/
&lt;/pre&gt;
&lt;h2 id=&quot;用来输出dbms_output-的类&quot;&gt;用来输出dbms_output 的类&lt;/h2&gt;
&lt;pre class=&quot;prettyprint linenums lang-java&quot;&gt;import java.sql.*;
class DbmsOutput 
 {
    /*
     * our instance variables. It is always best to use callable or prepared
     * statements and prepare (parse) them once per program execution, rather
     * then one per execution in the program. The cost of reparsing is very
     * high. Also -- make sure to use BIND VARIABLES!
     * 
     * we use three statments in this class. One to enable dbms_output -
     * equivalent to SET SERVEROUTPUT on in SQL*PLUS. another to disable it --
     * like SET SERVEROUTPUT OFF. the last is to &quot;dump&quot; or display the results
     * from dbms_output using system.out
     */
    private CallableStatement enable_stmt;

    private CallableStatement disable_stmt;

    private CallableStatement show_stmt;

    /*
     * our constructor simply prepares the three statements we plan on
     * executing.
     * 
     * the statement we prepare for SHOW is a block of code to return a String
     * of dbms_output output. Normally, you might bind to a PLSQL table type but
     * the jdbc drivers don&#39;t support PLSQL table types -- hence we get the
     * output and concatenate it into a string. We will retrieve at least one
     * line of output -- so we may exceed your MAXBYTES parameter below. If you
     * set MAXBYTES to 10 and the first line is 100 bytes long, you will get the
     * 100 bytes. MAXBYTES will stop us from getting yet another line but it
     * will not chunk up a line.
     */
    public DbmsOutput(Connection conn)
        throws SQLException {
        enable_stmt = conn.prepareCall(&quot;begin dbms_output.enable(:1); end;&quot;);
        disable_stmt = conn.prepareCall(&quot;begin dbms_output.disable; end;&quot;);
        show_stmt =
            conn.prepareCall(&quot;declare &quot;
                + &quot;    l_line varchar2(255); &quot;
                + &quot;    l_done number; &quot;
                + &quot;    l_buffer long; &quot;
                + &quot;begin &quot;
                + &quot;  loop &quot;
                + &quot;    exit when length(l_buffer)+255 &gt; :maxbytes OR l_done = 1; &quot;
                + &quot;    dbms_output.get_line( l_line, l_done ); &quot;
                + &quot;    l_buffer := l_buffer || l_line || chr(10); &quot;
                + &quot;  end loop; &quot; + &quot; :done := l_done; &quot;
                + &quot; :buffer := l_buffer; &quot; + &quot;end;&quot;);
    }

    /*
     * enable simply sets your size and executes the dbms_output.enable call
     */
    public void enable(int size)
        throws SQLException {
        enable_stmt.setInt(1, size);
        enable_stmt.executeUpdate();
    }

    /*
     * disable only has to execute the dbms_output.disable call
     */
    public void disable()
        throws SQLException {
        disable_stmt.executeUpdate();
    }

    /*
     * show does most of the work. It loops over all of the dbms_output data,
     * fetching it in this case 32,000 bytes at a time (give or take 255 bytes).
     * It will print this output on stdout by default (just reset what
     * System.out is to change or redirect this output).
     */
    public void show()
        throws SQLException {
        int done = 0;
        show_stmt.registerOutParameter(2, java.sql.Types.INTEGER);
        show_stmt.registerOutParameter(3, java.sql.Types.VARCHAR);
        for (;;) {
            show_stmt.setInt(1, 32000);
            show_stmt.executeUpdate();
            System.out.print(show_stmt.getString(3));
            if ((done = show_stmt.getInt(2)) == 1)
                break;
        }
    }

    /*
     * close closes the callable statements associated with the DbmsOutput
     * class. Call this if you allocate a DbmsOutput statement on the stack and
     * it is going to go out of scope -- just as you would with any callable
     * statement, result set and so on.
     */
    public void close()
        throws SQLException {
        enable_stmt.close();
        disable_stmt.close();
        show_stmt.close();
    }
}
&lt;/pre&gt;
&lt;h2 id=&quot;测试代码&quot;&gt;测试代码&lt;/h2&gt;
&lt;pre class=&quot;prettyprint linenums lang-java&quot;&gt;
import java.sql.*;
public class Test{
    public static void main(String args[])
        throws SQLException {
        DriverManager.registerDriver(new oracle.jdbc.driver.OracleDriver());
        Connection conn = DBAgent.getConn(); 
        conn.setAutoCommit(false);
        Statement stmt = conn.createStatement();
        DbmsOutput dbmsOutput = new DbmsOutput(conn);
        dbmsOutput.enable(1000000);
        stmt.execute(&quot;begin test_java_dbmsOutPut; end;&quot;); #调用存储过程
        stmt.close();
        dbmsOutput.show(); #显示DBMS_OUTPUT
        dbmsOutput.close();
        conn.close();
    }   
}
&lt;/pre&gt;
&lt;h2 id=&quot;输出的结果&quot;&gt;输出的结果&lt;/h2&gt;
&lt;p&gt;运行测试代码之后，就可以看见在java 控制台输出了: &lt;strong&gt;im in store procedure&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;这样就可以让java为我们输出DBMS_OUTPUT，就像SQL*PLUS一样。你需要做的仅仅是在java运行存储过程之后，调用DbmsOutput.show() ，就能显示这个存储过程内的DBMS_OUTPUT，是不是很方便？再也不用在eclipse和sql develper之间两头调试了&lt;/p&gt;
&lt;/blockquote&gt;
</description>
        </item>
        
        <item>
            <title>shadowsocks搭建代理</title>
            <link>Homepage link/articles/shadowsocks-proxy.html?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=rss</link>
            <guid>Homepage link/articles/shadowsocks-proxy.html</guid>
            <author>zxdy@vip.qq.com Ario</author>
            <pubDate>Fri, 13 Dec 2013 00:00:00 +0800</pubDate>
            <description>&lt;p&gt;今天openvpn貌似有点抽风， 不好使了。。。sigh。。
听说shadowsocks挺好用，就尝试了一下，确实还挺方便。记录一下搭建过程，基本上照官方的user manual来就ok了&lt;/p&gt;
&lt;h2 id=&quot;1-安装&quot;&gt;1. 安装&lt;/h2&gt;
&lt;pre class=&quot;prettyprint linenums lang-bash&quot;&gt;apt-get install python-pip python-dev build-essential
python --version #安装之前检查一下vps的python版本号，需要2.6或2.7以上
pip install shadowsocks #安装
&lt;/pre&gt;
&lt;h2 id=&quot;2-配置文件&quot;&gt;2. 配置文件&lt;/h2&gt;
&lt;p&gt;新建一个名为&lt;code&gt;config.json的配置文件&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-bash&quot;&gt;{
          &quot;server&quot;:&quot;vps的ip&quot;,
          &quot;server_port&quot;:8388,
          &quot;local_port&quot;:1080,
          &quot;password&quot;:&quot;barfoo!&quot;, #认证密码
          &quot;timeout&quot;:600,
          &quot;method&quot;:&quot;table&quot; #加密方式，默认table，推荐aes-256-cfb
}
&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;如果想用除table以外的加密方式，需要额外安装M2Crypto&lt;/em&gt;&lt;/p&gt;
&lt;pre class=&quot;prettyprint linenums lang-bash&quot;&gt;apt-get install python-m2crypto
#或者
pip install M2Crypto
&lt;/pre&gt;
&lt;h2 id=&quot;3进入-code-configjson-code-所在目录，运行shadowsocks&quot;&gt;3.进入&lt;code&gt;config.json所在目录，运行shadowsocks&lt;/h2&gt;
&lt;pre class=&quot;prettyprint linenums lang-bash&quot;&gt;nohup ssserver &gt; shadowsocks_log &amp;
&lt;/pre&gt;
&lt;h2 id=&quot;4客户端&quot;&gt;4.客户端&lt;/h2&gt;
&lt;p&gt;下载&lt;a href=&quot;http://sourceforge.net/projects/shadowsocksgui/files/dist/&quot;&gt;shadowsocks-gui&lt;/a&gt;，填入相应的vps ip地址，端口，密码信息后保存  &lt;/p&gt;
&lt;h2 id=&quot;5-浏览器代理&quot;&gt;5. 浏览器代理&lt;/h2&gt;
&lt;p&gt;新建socket5代理，地址填127.0.0.1，端口1080保存就可以使用了&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
